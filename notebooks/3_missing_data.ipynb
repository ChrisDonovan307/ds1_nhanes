{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMUTZlOJgwbi7WCZklu5y6D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Missing Data and Imputation\n","\n","Work in progress - converting the R script for missing data exploration and imputation into this jenky ass Colab script that makes everything a hundred times harder. Prioritizing the imputation right now so we can run it from Colab without shenanigans. Will add the graphs and tests here later.\n","\n","Note that the FNN package was not in the tar.gz file I added to drive, so we still have to install it manually and it takes a couple of minutes. Will redo this and load it locally to speed things up eventually."],"metadata":{"id":"oXbHJL-IwiXU"}},{"cell_type":"code","source":["%load_ext rpy2.ipython"],"metadata":{"id":"xg7DDfbw_IoA","executionInfo":{"status":"ok","timestamp":1745890840448,"user_tz":240,"elapsed":7951,"user":{"displayName":"Christopher Donovan","userId":"08763921350367890499"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["%%R\n","# Need to get hard copy of FNN and dependencies into drive.\n","# For now installing, and it takes a long time\n","install.packages('FNN', dependencies = TRUE, repos = \"https://cloud.r-project.org\")"],"metadata":{"id":"kEpOnvrUxOWT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DILRAC4KuicS"},"outputs":[],"source":["# If in colab, mount drive and set wd\n","# If local, set wd to parent of notebook\n","import os\n","import re\n","\n","try:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  os.chdir('/content/drive/MyDrive/ds1_nhanes/')\n","except:\n","  from pathlib import Path\n","  if not re.search(r'ds1_nhanes$', str(os.getcwd())):\n","    os.chdir(Path(os.getcwd()).parent)\n","\n","print(os.getcwd())"]},{"cell_type":"code","source":["%load_ext rpy2.ipython"],"metadata":{"id":"lkyftxyIuui0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R\n",".libPaths(c(\"dev/r_library/library\", .libPaths()))\n","print(.libPaths())"],"metadata":{"id":"gMaT7biEuvCF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R\n","library(dplyr)\n","library(missRanger)\n","library(stringr)"],"metadata":{"id":"lK6e6PM_u2Fs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R\n","raw <- read.csv('data/clean/nhanes_2017_2023_clean.csv')\n","str(raw)"],"metadata":{"id":"mwW7Jr2xvFTB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R\n","# Reduce to just the variables we want to impute - biomarkers and demographics\n","dat <- raw %>%\n","  select(\n","    gender:income_ratio,\n","    total_cholesterol,\n","    blood_mercury,\n","    avg_systolic_bp,\n","    avg_diastolic_bp\n","  )\n","str(dat)"],"metadata":{"id":"qXkq4BrSvRvU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%R\n","# missRanger imputation\n","imp <- missRanger(\n","  dat,\n","  pmm.k = 5,\n","  num.trees = 100,\n","  seed = 42,\n","  keep_forests = TRUE,\n","  verbose = 1\n",")\n","print(summary(imp))\n","\n","# Check errors\n","print(imp$mean_pred_errors)\n","\n","# Best errors\n","print(imp$pred_errors[2, ])"],"metadata":{"id":"jRyj4970vXiZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Put the DF back together so we can save it"],"metadata":{"id":"6iWmRdBfyTpu"}},{"cell_type":"code","source":["%%R\n","\n","# Combine back with full\n","df <- raw %>%\n","  select(-all_of(c(names(imp$data))))\n","# str(df)\n","\n","# Combine\n","df <- bind_cols(df, imp$data)\n","# str(df)\n","\n","# Remove extra biomarkers\n","# Also removing income ratio qs - will have to recreate it after imp\n","df <- df %>%\n","  select(\n","      -c(cholesterol_std_dev:serum_ferritin),\n","      -income_ratio_qs\n","    )\n","# str(df)\n","\n","# Get parenthesis back into col names\n","# (R automatically converted them to periods)\n","names(df) <- names(df) %>%\n","  str_replace('\\\\.', '\\\\(') %>%\n","  str_replace('eq\\\\.', 'eq\\\\)') %>%\n","  str_replace('drinks\\\\.', 'drinks\\\\)') %>%\n","  str_replace('grams\\\\.', 'grams\\\\)')\n","str(df)"],"metadata":{"id":"wJePY8WWySvW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save as csv"],"metadata":{"id":"omDqMKgczZGl"}},{"cell_type":"code","source":["%%R\n","write.csv(df, 'data/clean/nhanes_2017_2023_imputed.csv')"],"metadata":{"id":"6Ivav-QszXhS"},"execution_count":null,"outputs":[]}]}